{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Neural Algorithm of Arctic Style 画風変換  \n",
    "  \n",
    "  \n",
    "\n",
    "**このプログラムの説明はQiitaの記事にもしておりますので、ご覧ください。**  \n",
    "[TensorFlowで画風変換を少し説明しつつ実装してみる](https://qiita.com/isboj/items/4e25f0bd0a2577d7b857)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGGの学習済みの重みを利用します。その為、MATLABのmat形式で配布されているファイルをダウンロードします。\n",
    "URL: http://www.vlfeat.org/matconvnet/pretrained/  \n",
    "(VGG-VDモデルの、imagenet-vgg-verydeep-19.matをダウンロードします。)  \n",
    "今回は、ダウンロードしたファイルを  \n",
    "`[カレントディレクトリ]>[models]`  \n",
    "に保存しています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画風変換に利用する画像を設定していきます。  \n",
    "スタイル画像の特徴をコンテンツ画像に適用していき、その結果が生成画像として出力されます。  \n",
    "また、生成画像は最適化回数ごとに出力されますので、ディレクトリを指定します。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTENT_IMG = 'images/SetoBridge.jpg'  # コンテンツ画像（jpgでないとダメ）\n",
    "STYLE_IMG = 'images/StarryNight.jpg'  # スタイル画像（jpgでないとダメ）\n",
    "\n",
    "OUTPUT_DIR = 'results'  # 生成画像ディレクトリ\n",
    "OUTPUT_IMG = 'Seto'  # 生成画像ファイル名\n",
    "\n",
    "VGG_MODEL = \"models/imagenet-vgg-verydeep-19.mat\" #matファイルのある場所\n",
    "\n",
    "STYLE_STRENGTH = 500 # スタイルの強さ\n",
    "ITERATION = 100 # 最適化回数（CPUなら100回くらい、GPUなら10000回くらいか）\n",
    "SPAN_OUTPUT = 5 # 何回に1回出力するか"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "##import imageio\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGGは600×300×3の画像を想定しているので、それぞれのサイズを設定する。  \n",
    "平均値をゼロにするため、VGGの訓練データの平均画素値[123.68, 116.779, 103.939]を引かなければならない。(その為、平均画素値はVGGモデルにより異なる。)　　\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  入力画像から平均画素値を引くための定数(reshapeでそのまま引けるようにする)\n",
    "MEAN_VALUES = np.array([123, 117, 104]).reshape((1,1,1,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ネットワークの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_net(ntype, nin, rwb=None):\n",
    "    \"\"\"\n",
    "    ネットワークの各層をTensorFlowで定義する関数\n",
    "    : param ntype: ネットワークの層のタイプ(ここでは、畳み込み層もしくは、プーリング層)\n",
    "    : param nin: 前の層\n",
    "    : param rwb: VGGの最適化された値\n",
    "    \"\"\"\n",
    "    if ntype == 'conv':\n",
    "        return tf.nn.relu(tf.nn.conv2d(nin, rwb[0], strides=[1, 1, 1, 1], padding='SAME') + rwb[1])\n",
    "    elif ntype == 'pool':\n",
    "        return tf.nn.avg_pool(nin, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight_bias(vgg_layers, i):\n",
    "    \"\"\"\n",
    "    VGGの各層の最適化された重みとバイアスを取得する関数\n",
    "    : param vgg_layers: ネットワークの層\n",
    "    : param i:\n",
    "    \"\"\"\n",
    "    weights = vgg_layers[i][0][0][2][0][0]\n",
    "    weights = tf.constant(weights)\n",
    "    bias = vgg_layers[i][0][0][2][0][1]\n",
    "    bias = tf.constant(np.reshape(bias, (bias.size)))\n",
    "    return weights, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vgg19(path):\n",
    "    \"\"\"\n",
    "    TensorFlowでVGGネットワークを構成する関数\n",
    "    : param path: VGGの学習済みモデルのファイルのパス\n",
    "    \"\"\"\n",
    "    net = {}\n",
    "    vgg_rawnet = scipy.io.loadmat(path)\n",
    "    vgg_layers = vgg_rawnet['layers'][0]\n",
    "    net['input'] = tf.Variable(np.zeros((1, IMAGE_H, IMAGE_W, 3)).astype('float32'))\n",
    "    net['conv1_1'] = build_net('conv',net['input'],get_weight_bias(vgg_layers,0))\n",
    "    net['conv1_2'] = build_net('conv',net['conv1_1'],get_weight_bias(vgg_layers,2))\n",
    "    net['pool1']   = build_net('pool',net['conv1_2'])\n",
    "    net['conv2_1'] = build_net('conv',net['pool1'],get_weight_bias(vgg_layers,5))\n",
    "    net['conv2_2'] = build_net('conv',net['conv2_1'],get_weight_bias(vgg_layers,7))\n",
    "    net['pool2']   = build_net('pool',net['conv2_2'])\n",
    "    net['conv3_1'] = build_net('conv',net['pool2'],get_weight_bias(vgg_layers,10))\n",
    "    net['conv3_2'] = build_net('conv',net['conv3_1'],get_weight_bias(vgg_layers,12))\n",
    "    net['conv3_3'] = build_net('conv',net['conv3_2'],get_weight_bias(vgg_layers,14))\n",
    "    net['conv3_4'] = build_net('conv',net['conv3_3'],get_weight_bias(vgg_layers,16))\n",
    "    net['pool3']   = build_net('pool',net['conv3_4'])\n",
    "    net['conv4_1'] = build_net('conv',net['pool3'],get_weight_bias(vgg_layers,19))\n",
    "    net['conv4_2'] = build_net('conv',net['conv4_1'],get_weight_bias(vgg_layers,21))\n",
    "    net['conv4_3'] = build_net('conv',net['conv4_2'],get_weight_bias(vgg_layers,23))\n",
    "    net['conv4_4'] = build_net('conv',net['conv4_3'],get_weight_bias(vgg_layers,25))\n",
    "    net['pool4']   = build_net('pool',net['conv4_4'])\n",
    "    net['conv5_1'] = build_net('conv',net['pool4'],get_weight_bias(vgg_layers,28))\n",
    "    net['conv5_2'] = build_net('conv',net['conv5_1'],get_weight_bias(vgg_layers,30))\n",
    "    net['conv5_3'] = build_net('conv',net['conv5_2'],get_weight_bias(vgg_layers,32))\n",
    "    net['conv5_4'] = build_net('conv',net['conv5_3'],get_weight_bias(vgg_layers,34))\n",
    "    net['pool5']   = build_net('pool',net['conv5_4'])\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_content_loss(p, x):\n",
    "    \"\"\"\n",
    "    コンテンツと出力の誤差\n",
    "    \"\"\"\n",
    "    M = p.shape[1]*p.shape[2]\n",
    "    N = p.shape[3]\n",
    "    loss = (1./(2* N**0.5 * M**0.5 )) * tf.reduce_sum(tf.pow((x - p),2))  \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(x, area, depth):\n",
    "    \"\"\"\n",
    "    個々のフィルタ出力の相関をグラム行列で表現\n",
    "    \"\"\"\n",
    "    x1 = tf.reshape(x,(area,depth))\n",
    "    g = tf.matmul(tf.transpose(x1), x1)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix_val(x, area, depth):\n",
    "    \"\"\"\n",
    "    スタイル自体もグラム行列で表現\n",
    "    \"\"\"\n",
    "    x1 = x.reshape(area,depth)\n",
    "    g = np.dot(x1.T, x1)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_style_loss(a, x):\n",
    "    \"\"\"\n",
    "    スタイルと出力の誤差\n",
    "    \"\"\"\n",
    "    M = a.shape[1]*a.shape[2]\n",
    "    N = a.shape[3]\n",
    "    A = gram_matrix_val(a, M, N )\n",
    "    G = gram_matrix(x, M, N )\n",
    "    loss = (1./(4 * N**2 * M**2)) * tf.reduce_sum(tf.pow((G - A),2))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path, IMAGE_SIZE=(0,0)):\n",
    "    \"\"\"\n",
    "    画像を読み込む関数\n",
    "    \"\"\"\n",
    "    image = scipy.misc.imread(path)\n",
    "    if IMAGE_SIZE==(0,0):\n",
    "        IMAGE_SIZE = (image.shape[0], image.shape[1])\n",
    "    image = scipy.misc.imresize(image,IMAGE_SIZE)\n",
    "    image = image[np.newaxis,:,:,:] \n",
    "    image = image - MEAN_VALUES\n",
    "    return image, IMAGE_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_image(path, image):\n",
    "    \"\"\"\n",
    "    生成された画像を保存する関数\n",
    "    \"\"\"\n",
    "    image = image + MEAN_VALUES\n",
    "    image = image[0]\n",
    "    image = np.clip(image, 0, 255).astype('uint8')\n",
    "    scipy.misc.imsave(path, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像の読み込み\n",
    "content_img, (IMAGE_H, IMAGE_W)= read_image(CONTENT_IMG)\n",
    "style_img, (IMAGE_H, IMAGE_W) = read_image(STYLE_IMG, (IMAGE_H, IMAGE_W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(content_img.shape)\n",
    "print(style_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG19モデルの作成\n",
    "net = build_vgg19(VGG_MODEL)\n",
    "# ホワイトノイズ\n",
    "noise_img = np.random.uniform(-20, 20, (1, IMAGE_H, IMAGE_W, 3)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初期化\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "画風変換の出力を調節するにはここを変更\n",
    "\"\"\"\n",
    "# 各種パラメータの設定\n",
    "INI_NOISE_RATIO = 0.7 # ホワイトノイズの重み\n",
    "\n",
    "# コンテンツ画像と出力画像で誤差を取る層\n",
    "CONTENT_LAYERS =[('conv4_2',1.)]\n",
    "# スタイル画像と出力画像で誤差を取る層\n",
    "STYLE_LAYERS=[('conv1_1',1.),('conv2_1',1.),('conv3_1',1.),('conv4_1',1.),('conv5_1',1.)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run([net['input'].assign(content_img)])\n",
    "cost_content = sum(map(lambda l,: l[1]*build_content_loss(sess.run(net[l[0]]) ,  net[l[0]]), CONTENT_LAYERS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run([net['input'].assign(style_img)])\n",
    "cost_style = sum(map(lambda l: l[1]*build_style_loss(sess.run(net[l[0]]) ,  net[l[0]]), STYLE_LAYERS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_total = cost_content + STYLE_STRENGTH * cost_style\n",
    "optimizer = tf.train.AdamOptimizer(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = optimizer.minimize(cost_total)\n",
    "sess.run( tf.global_variables_initializer())\n",
    "sess.run(net['input'].assign( INI_NOISE_RATIO* noise_img + (1.-INI_NOISE_RATIO) * content_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存先ディレクトリが存在しないときは作成\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.mkdir(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(ITERATION):\n",
    "    sess.run(train)\n",
    "    # SPAN_OUTPUT回ごとに経過を表示、画像を保存\n",
    "    if i%SPAN_OUTPUT ==0:\n",
    "        result_img = sess.run(net['input'])\n",
    "        print (\"ITERATION: \",i,\", \",sess.run(cost_total))\n",
    "        write_image(os.path.join(OUTPUT_DIR,OUTPUT_IMG + '%s.png'%(str(i).zfill(4))),result_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_image(os.path.join(OUTPUT_DIR,OUTPUT_IMG + \".png\"),result_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
